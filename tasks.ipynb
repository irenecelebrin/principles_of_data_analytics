{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysing the Iris dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing libraries "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before starting the analysis of the Iris dataset, all the external Libraries required to run the notebook are imported. \n",
    "\n",
    "If the code is run locally and these libraries are not already installed in the local machine, they need to be installed (see README for more information). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import scikit-learn\n",
    "import sklearn as skl\n",
    "\n",
    "# import numpy \n",
    "import numpy as np\n",
    "\n",
    "# import pandas\n",
    "import pandas as pd\n",
    "\n",
    "# import matplotlib.pyplot \n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# import matplotlib.lines\n",
    "from matplotlib.lines import Line2D\n",
    "\n",
    "# import scipy\n",
    "import scipy as sp\n",
    "\n",
    "# import seaborn\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Sourcing the Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### About the dataset "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Iris flower dataset was created by the British biologist and statistician Ronald Fisher and first published in 1936 in *The use of multiple measurements in taxonomic problems*. The dataset includes 150 samples (50 each) from 3 different species of Iris flower (Setosa, Versicolor, Virginica). For each sample in the dataset, 5 variable are provided, i.e. 4 features and 1 target class: \n",
    "\n",
    "- Sepal length\n",
    "- Sepal width\n",
    "- Petal length\n",
    "- Petal width \n",
    "- Iris species\n",
    "\n",
    "The dataset was used by Fisher himself as an example for Linear Discriminant Analysis. The goal of LDA is to find a Linear Combination (or direct correlation) between features to prove that they characterise or separate given classes of objects (in this case, the 3 iris species). This means that with the iris dataset a user can find and analyse the correlation of 2 or more features in the dataset. For example, by looking at the features of a sample, the corresponding iris species can be guessed. (source: [Linear discriminant analysis](https://en.wikipedia.org/wiki/Linear_discriminant_analysis)).\n",
    "\n",
    "The Iris dataset is commonly used as a beginner's dataset to approach machine learning for classification, data mining and clustering (source: [Data Science Example - Iris dataset](http://www.lac.inpe.br/~rafael.santos/Docs/CAP394/WholeStory-Iris.html)])."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sourcing the dataset "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset can be sourced in multiple vays:\n",
    "1) It can be imported through the library scikit-learn, using the load_iris() function. In this way, the data can be viewed, manipulated, and extracted with numpy. This function also allows to view more information on the dataset, such as numerical characteristics of the daa, and references on its use throughout scientific literature (source: [Scikit learn](https://scikit-learn.org/stable/modules/generated/sklearn.datasets.load_iris.html)).\n",
    "\n",
    "2) It can be imported uploading a file with tabular format. The file can be later converted to a pandas dataframe to explore the data, extract it, and represent it. \n",
    "\n",
    "3) It can be imported through other libraries, such as [UC Irvine Machine Learning Repository](https://archive.ics.uci.edu/dataset/53/iris), and using pandas to convert it to a dataframe. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this projects, the dataset is imported through the load_iris function, and uploading a .csv file. In this way, the data is explored showing two different methods. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1) load the dataset from scikit-learn\n",
    "# see https://scikit-learn.org/stable/modules/generated/sklearn.datasets.load_iris.html \n",
    "data = skl.datasets.load_iris()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2) upload the dataset uploading a file with tabular format\n",
    "data_tabular = pd.read_csv('https://gist.githubusercontent.com/curran/a08a1080b88344b0c8a7/raw/0e7a9b0a5d22642a06d3d5b9bcbad9890c8ee534/iris.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Exploring the data structure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploring the dataset with load_iris()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the load_iris() function, the dataset can be printed out in its entirety. In particular, the data is provided in the form of a a 'bunch', which is a dictionary-like object with a number of elements (features, targets, feature and target names, frame, description...). Using the functions associated with each key, individual elecments can be explored. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show keys \n",
    "print(data.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Keys in the dataset: \n",
    "\n",
    "- **data (features)** a 2-D array listing the 4 features of each instance in the data set. Each value is a float. Each featue corresponds to a column. \n",
    "\n",
    "- **target** a 1-D array (list) with the target class of each instance, expressed in integers (0, 1, 2). \n",
    "\n",
    "- **frame** how the data is structured (tabular format or not). \n",
    "\n",
    "- **target_names** strings with the iris species associated with the target values (Setosa, Versicolor, Virginica). This is also a 2-D array, composed of a list of strings (flower names), and a value describing the data type (string: Unicode characters, longest string is less than 10 characters). My reference: https://ds100.org/fa17/assets/notebooks/numpy/Numpy_Review.html. \n",
    "\n",
    "- **description** a short description of the data set, including number of instances, features, classes -- the one printed above. \n",
    "\n",
    "- **feature_names** 1-D array: a list with strings representing the 4 feature names (Sepal length, Sepal width, Petal length, Petal Width). \n",
    "\n",
    "- **file_name** name of the .csv file \n",
    "\n",
    "- **data_module** the source, sklearn.datasets. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the function **data.DESCR**, a detailed description of the dataset can be produced. The summary provides information on the size of the dataset, variables  (features & targets) number and names, and mathematical operations on the features (min, max, mean, sd, median) and correlation degree between the features. The summary also includes further information on the dataset, its author and literature references. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show dataset description \n",
    "print(data.DESCR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the functions associated with **target_names** and **features**, names can be printed in the form of arrays. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show target names\n",
    "data.target_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show feature names \n",
    "data.feature_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, the dataset can be viewed in its entirety either as a bunch, as mentioned above, i.e. including data & metadata, or as a tuple of two arrays, showing only the data, i.e. features and targets. In that case, the data can be represented in a tabular format, with feature names on top of the columns. This can be done setting the parameters *return_X_y=True* (to show only features and targets) and *as_frame=True* (for the tabular format). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# uncomment to view data as a bunch \n",
    "# data\n",
    "\n",
    "# uncomment to view only features and targets\n",
    "data_framed = skl.datasets.load_iris(as_frame=True, return_X_y=True)\n",
    "\n",
    "data_framed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploring the dataset with pandas "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the previous task, the dataset was imported through a .csv file and converted to a pandas dataframe. \n",
    "\n",
    "The dataframe allows to view features and target togheter, and select individual/multiple columns and rows. For this reason, it is easier to used pandas to select, for example, all the samples with the same target value.\n",
    "\n",
    "Below, the data is vievisualized as a dataframe: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show dataframe \n",
    "data_tabular"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Summarizing the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section, features are extracted to carry out some mathemcatical operations. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extracting the features "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Features are extracted from the dataset and stored in the variable *features*. \n",
    "The variable is a 2-D array. It contains multiple arrays, one for each sample in the dataset. Every array includes 4 values (one for each feature of the dataset), in this order: \n",
    "- sepal length \n",
    "- sepal width\n",
    "- petal length\n",
    "- petal width"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# variable for features\n",
    "features = data.data \n",
    "\n",
    "# show features\n",
    "features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using Numpy for mathematical operations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Numpy functions are then used to calculate the following values for each feature (column) in the dataset. \n",
    "\n",
    "The functions take in an array. Setting the *axis* paramter, it is possible to specify along which axis the values are computed, in this case column-wise. If no axis is specified, the result is the mean of the flattened array. \n",
    "\n",
    "Links to the official documentation: \n",
    "- **mean**: [numpy.mean](https://numpy.org/doc/stable/reference/generated/numpy.mean.html)\n",
    "- **minimum**: [numpy.min](https://numpy.org/doc/stable/reference/generated/numpy.min.html)\n",
    "- **maximum**: [numpy.max](https://numpy.org/doc/stable/reference/generated/numpy.max.html)\n",
    "- **standard deviation**: [numpy.std](https://numpy.org/doc/stable/reference/generated/numpy.std.html)\n",
    "- **median**: [numpy.median](https://numpy.org/doc/stable/reference/generated/numpy.median.html)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mean \n",
    "print(f'Mean:\\t\\t\\t{np.mean(features, axis=0)}')\n",
    "\n",
    "# minimum\n",
    "print(f'Minimum:\\t\\t{np.min(features, axis=0)}')\n",
    "\n",
    "# maximum\n",
    "print(f'Maximum:\\t\\t{np.max(features, axis=0)}')\n",
    "\n",
    "# standard deviation\n",
    "print(f'Standard Deviation:\\t{np.std(features, axis=0)}')\n",
    "\n",
    "# mean \n",
    "print(f'Median:\\t\\t\\t{np.median(features, axis=0)}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**About the features**\n",
    "\n",
    "- **mean**\n",
    "\n",
    "In this case, it is the arithmetic mean, or average: 'The sum of values divided by the number of values' ([Wikipedia](https://en.wikipedia.org/wiki/Mean)). \n",
    "\n",
    "- **minimum**\n",
    "\n",
    "The lowest value in the array ([Wikipedia](https://en.wikipedia.org/wiki/Maximum_and_minimum)).\n",
    "\n",
    "Petal width is the feature with the lowest minimum, Sepal length the feature with the greatest minimum value. \n",
    "\n",
    "- **maximum**\n",
    "\n",
    "The greatest value in the array ([Wikipedia](https://en.wikipedia.org/wiki/Maximum_and_minimum)).\n",
    "\n",
    "Again, Petal width is the feature with the lowest maximum value, Sepal length the one with the greatest maximum value. \n",
    "\n",
    "- **standard deviation**. \n",
    "\n",
    "'The average amount of variability in your dataset. It tells you, on average, how far each value lies from the mean.' ( [Pritha Bhandari, How to Calculate Standard Deviation (Guide) | Calculator & Examples](https://www.scribbr.com/statistics/standard-deviation/#:~:text=The%20standard%20deviation%20is%20the,clustered%20close%20to%20the%20mean).)\n",
    "\n",
    "In this case, petal length is the feature that varies the most across the datasets, with a standard deviation that is two to three times that of the other features: 1.75 vs 0.82. 0.43, 0.75.\n",
    "\n",
    "- **median** \n",
    "\n",
    "'The middle term of the given set of data if the data is arranged either in ascending or descending order' ([Median in statistics](https://www.geeksforgeeks.org/median/)). It differs from mean because it is not necessarily the average of a set of values, only the value that is exactly in the middle. \n",
    "\n",
    "In this case, the mean and the median of Sepal length and width are similar, while those of Petal length and petal width are significantly different. \n",
    "\n",
    "Petal length: mean = 3.758; median = 4.35   | Petal width: mean = 1.19933333; median: 1.3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Visualizing features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this task, plots are created to visualize each feature in the Iris dataset and observe feature distribution and variation. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accessing each feature in the dataset\n",
    "\n",
    "In order to plot the data, the *features* array is sliced to extract individial 1-D arrays corresponding to each feature, so that they can be named and plotted individually. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sepal length \n",
    "sepal_length = features[:,0]\n",
    "# Sepal width \n",
    "sepal_width = features[:,1]\n",
    "# Petal lenght\n",
    "petal_length = features[:,2]\n",
    "# Petal width \n",
    "petal_width = features[:,3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment any of these to verify the arrays are correct, or check how they look like. \n",
    "\n",
    "#sepal_length\n",
    "#sepal_width\n",
    "#petal_length\n",
    "#petal_width"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Histograms\n",
    "\n",
    "**Plotting features individually**\n",
    "\n",
    "Matplotlib.pyplot was used to plot histograms for each feature individually.\n",
    "In this case, a stateful approach (pyplot) was enough to be able to show all elements and differentiate them. \n",
    "About stateful vs stateless (or object-oriented) approach on Matplotlib: [Pyplot vs Object-oriented interface](https://matplotlib.org/matplotblog/posts/pyplot-vs-object-oriented-interface/), [Matplotlib essentials](https://medium.com/@The_Gambitier/matplotlib-essentials-e376ed954201).\n",
    "\n",
    "To plot the histograms, the official documenation on matplotlib was referenced: [matplotlib.pyplot.hist](https://matplotlib.org/stable/api/_as_gen/matplotlib.pyplot.hist.html). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Histogram for Sepal length\n",
    "# color on Matplotlib: https://matplotlib.org/stable/gallery/color/named_colors.html  \n",
    "plt.hist(sepal_length, color = 'seagreen', edgecolor = 'mediumseagreen')\n",
    "# add labels to axes and title \n",
    "plt.xlabel('Dimensions (in cm)')\n",
    "plt.ylabel('N. in the dataset')\n",
    "plt.title('Sepal length')\n",
    "# show data \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With regard to Sepal length, it looks like most of the samples are 4.5-6.8cm, while only few are shorter or longer than that.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sepal width \n",
    "plt.hist(sepal_width, color = 'lightgreen', edgecolor = 'palegreen')\n",
    "# Add labels and title\n",
    "plt.title('Sepal width')\n",
    "plt.xlabel('Dimensions (in cm)')\n",
    "plt.ylabel('N. in the dataset')\n",
    "# Show \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With regard to Sepal width, most of the samples are close to the median value. That means that the standard deviation is relatively low, and that only few samples are close to the minimum and maximum value. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Petal length\n",
    "plt.hist(petal_length, color = 'darkorchid', edgecolor = 'mediumorchid')\n",
    "# Add labels and title\n",
    "plt.title('Petal length')\n",
    "plt.xlabel('Dimensions (in cm)')\n",
    "plt.ylabel('N. in the dataset')\n",
    "# Show\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With regard to Petal length, many samples are located at the lower end of the range, close to the minimum value. Then there is a gap, after which values increase again, to dicrease towards the maximum value. In this case, standard deviation is quite high (1.75940407, more than double than the highest Sd of the other samples). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Petal width \n",
    "plt.hist(petal_width, color = 'plum', edgecolor = 'thistle')\n",
    "plt.title('Petal width')\n",
    "plt.xlabel('Dimensions (in cm)')\n",
    "plt.ylabel('N. in the dataset')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With regard to Petal width, the distribution of samples looks somehow similar to that of Petal length. There is a peak at the lower end of the range, then a drop, and then an increase again. It would be interesting to visualize this in a scatter plot, to verify if a correlation exists and what that it. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**EXTRA: Plotting all the features together**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#set colors \n",
    "edgecolorss = ['#2E8B57','#90EE90','#9932CC','#DDA0DD']\n",
    "colors = ['seagreen','lightgreen', 'darkorchid', 'plum']\n",
    "\n",
    "# plot the histogram \n",
    "plt.hist(sepal_length, color = 'seagreen', edgecolor = 'mediumseagreen', label= 'Sepal length')\n",
    "plt.hist(sepal_width, color = 'lightgreen', edgecolor = 'palegreen', label = 'Sepal width')\n",
    "plt.hist(petal_length, color = 'darkorchid', edgecolor = 'mediumorchid', label = 'Petal length')\n",
    "plt.hist(petal_width, color = 'plum', edgecolor = 'thistle', label = 'Petal width')\n",
    "plt.title('Iris features')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It does not look like plotting the histograms together can highlight any valuable insights. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extra: comparing feature variation with boxplots "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since visualizing features together in the same histogram is not insightful, boxplots are created to show feature variation with regard to minimum, maximum, distribution, and any outliers ([What Is a Boxplot?](https://builtin.com/data-science/boxplot#:~:text=A%20boxplot%20is%20a%20graph,in%20comparison%20to%20the%20IQR.)). \n",
    "\n",
    "In this case, a stateless (or object-oriented) approach was used to be able to leverage artist personalization when plotting the data (in particular with regard to colors). \n",
    "More information on boxplot plotting was found in the official documentation: [matplotlib.axes.Axes.boxplots](https://matplotlib.org/stable/api/_as_gen/matplotlib.axes.Axes.boxplot.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set labels\n",
    "feature_labels = []\n",
    "for name in data.feature_names:\n",
    "    feature_label = name.replace(' (cm)','').capitalize()\n",
    "    feature_labels.append(feature_label)\n",
    "\n",
    "# set colors \n",
    "colors = ['seagreen','lightgreen', 'darkorchid', 'plum']\n",
    "median_color = dict(color = 'red', linewidth = 1.5 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a boxplot to compare variation in the 4 features \n",
    "# see https://matplotlib.org/stable/api/_as_gen/matplotlib.axes.Axes.boxplot.html \n",
    "\n",
    "# Create subplot\n",
    "fig, ax = plt.subplots() \n",
    "\n",
    "# Plot boxplots\n",
    "# Subplot includes different colors for each feature boxplot, ticks and labels for each feature \n",
    "# about medianprops: https://stackoverflow.com/questions/57668399/change-the-colors-of-outline-and-median-lines-of-boxplot-in-matplotlib \n",
    "feature_plot = ax.boxplot(features, patch_artist=True, medianprops= median_color, tick_labels=feature_labels)\n",
    "\n",
    "\n",
    "# assign colors to each feature boxplot \n",
    "# more here: https://matplotlib.org/stable/gallery/statistics/boxplot_color.html#sphx-glr-gallery-statistics-boxplot-color-py\n",
    "for patch, color in zip(feature_plot['boxes'], colors):\n",
    "    patch.set_facecolor(color) \n",
    "\n",
    "# add title \n",
    "ax.set_title('Feature variation')\n",
    "# add x ticks and labels for each boxplot \n",
    "# see https://matplotlib.org/stable/api/_as_gen/matplotlib.axes.Axes.set_xticks.html#matplotlib.axes.Axes.set_xticks\n",
    "#plt.xticks([1,2,3,4], feature_names)\n",
    "# add labels for axes \n",
    "ax.set_xlabel('Features')\n",
    "ax.set_ylabel('Measure (in cm)')\n",
    "\n",
    "# show plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What the plot highlights: \n",
    "- Sepal width has the lowest degree of variation, but also outliers at the ends. \n",
    "- Petal length has the highest degree of variation, with the median value very close to the third quartile. \n",
    "- As for Sepal length, it looks like first and third quartile have a similar distance to median value. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Investigating relationships "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section, correlations between Petal length and Petal width are analysed and visualized with a scatter plot. A stateless approach is used ([Matplotlib essentials](https://medium.com/@The_Gambitier/matplotlib-essentials-e376ed954201)). \n",
    "\n",
    "About scatter plots: [matplotlib.pyplot.scatter](https://matplotlib.org/stable/api/_as_gen/matplotlib.pyplot.scatter.html). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare the data\n",
    "# Capitalize target names, and store target names in a list \n",
    "target_labels = []\n",
    "for target in data.target_names:\n",
    "    target_label = target.capitalize()\n",
    "    target_labels.append(target_label)\n",
    "\n",
    "# Create variable for target data\n",
    "targets = data.target\n",
    "\n",
    "# Set colors for each class \n",
    "# Colors https://jamesmccaffrey.wordpress.com/2020/10/22/making-a-python-scatter-plot-with-different-colors-for-different-labels/ \n",
    "target_colormap = np.array(['orchid', 'mediumvioletred', 'pink'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the plot \n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "# Plot the data \n",
    "# About markers: https://matplotlib.org/stable/api/markers_api.html#module-matplotlib.markers \n",
    "plot = ax.scatter(petal_length,petal_width, c=target_colormap[targets], marker='8')\n",
    "ax.set_xlabel('Petal length')\n",
    "ax.set_ylabel('Petal width')\n",
    "ax.set_title('Iris petal size')\n",
    "\n",
    "# Create custom legend using target_labels\n",
    "# from chatGPT https://chatgpt.com/share/67f2c42b-a108-800f-9b47-c15d529b5264 \n",
    "legend_elements = [Line2D([0], [0], marker='8', color='w', label=label,\n",
    "                          markerfacecolor=color, markersize=10)\n",
    "                   for label, color in zip(target_labels, target_colormap)]\n",
    "ax.legend(handles=legend_elements, loc=\"upper left\", title=\"Iris variety\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The hypothesis formulated with the histograms is confirmed: there is a direct postive correlation between Petal width and Petal length: the longer the petal, the bigger it is. \n",
    "Also, the class coloring highlights the fact that the three different target classes are homogeneous and have consistent size dimensions. In particular: \n",
    "\n",
    "- Iris Setosa has smaller dimentions, and smaller variation among its samples.\n",
    "- Iris Versicolor has bigger dimensions and variation than Setosa, but smaller than Virginica. The samples towards the maximums overlap with Virginica samples. \n",
    "- Iris Virginica is the class with the highest degree of variation and highest dimentions. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Analysing relationships "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section numpy.polyfit is used to fit a line in the scatter plot from Task 6. In this way, an equation can be found to represent the correlation between Petal length and Petal width in the three Iris species. \n",
    "\n",
    "Line fitting is used as part of **Simple Linear Regression**. The goal of Simple Linear Regression is to represent the replationship between two variables (an independent  and a dependent variable) and, evetually, be able to calculate the value of a dependent variable based on the value of an independent variable ([wikipedia])(https://en.wikipedia.org/wiki/Simple_linear_regression). Simple Linear Regression is calculated using an equation: this equation can also be used to plot a line that fits the data, i.e. highlights a trend in the data. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculating slope and intercept"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, the values of **Slope** (m) and **Intercept** (c) of the ideal line representing the relationship between the variables are calculated with [numpy.polyfit](https://numpy.org/doc/stable/reference/generated/numpy.polyfit.html). These value will be used to calculate the equation of the line fitting the data. \n",
    "\n",
    "The Slope represents the steepness of the line ([W3school](https://www.w3schools.com/datascience/ds_linear_slope.asp)). The Intercept is the point where the line intersects with an axis, that is, the value of Y when X=0. ([Minitab](https://support.minitab.com/en-us/minitab/help-and-how-to/statistical-modeling/regression/supporting-topics/basics/slope-and-intercept-of-the-regression-line/))."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit a line to the data \n",
    "m , c = np.polyfit(petal_length, petal_width, 1)\n",
    "\n",
    "# show \n",
    "m, c"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the equation **y = mx + c**, and leveraging the values of **m** and **c** calculated with polyfit, the relationship between the two variables is found. This equation is then used to plot a line in the scatter plot created in the previous Task.   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate line equation \n",
    "polyfit_equation = (f'W = {m:.2f}L + {c:.2f}')\n",
    "\n",
    "polyfit_equation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Line fitting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The scatter plot from Task 5 is recreated, and a line added to highlight the relationship between the variables. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recreate the scatter plot \n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "# plot the data \n",
    "# about markers: https://matplotlib.org/stable/api/markers_api.html#module-matplotlib.markers \n",
    "plot = ax.scatter(petal_length,petal_width, c=target_colormap[targets], marker='8')\n",
    "ax.set_xlabel('Petal length (L)')\n",
    "ax.set_ylabel('Petal width (W)')\n",
    "ax.set_title('Iris petal size')\n",
    "\n",
    "# add line to the plot \n",
    "polyfit_line = ax.plot(petal_length, m * petal_length + c, color='blue', label = polyfit_equation);\n",
    "\n",
    "ax.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at the line, it is possible to notice that some sample are closer to the line (mostly Setosa and Versicolor samples), while others are farther away (mostly Virginica samples). This means that the line is more precise in describing the trend for Setosa and Versicolor species, while for Virginica it is less precise. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Analysing class distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section, boxplots are used to analyse class distribution. A boxplot is created to represent the feature Petal length for each target (Iris species) in the dataset. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating the variables\n",
    "\n",
    "To make it easier to extract feature values and separate them according to the class, the dataset imported from a .csv file and converted to a Pandas dataframe is used instead of that imported with scikit learn (load_iris()). \n",
    "\n",
    "**Why?**\n",
    "\n",
    "Load_iris() only allows to view features and targets at the same time as a bunch (*data()*) or as a tuple of two arrays (*data(return_X_y = True)*). If features and targets are stored in two separate arrays, it is harder to extract values in one array based on the corresponding value in another array. The two arrays should be extracted separately and combined. \n",
    "On the other hand, a Pandas dataframe allows to select rows based on a given condition (in this case, target value), and from there select specific series/values (Petal length). \n",
    "\n",
    "References: \n",
    "- load_iris() properties https://scikit-learn.org/stable/modules/generated/sklearn.datasets.load_iris.html\n",
    "- Analyse the iris dataset with pandas https://www.geeksforgeeks.org/box-plot-and-histogram-exploration-on-iris-data/\n",
    "- Select rows in pandas dataframe https://www.geeksforgeeks.org/selecting-rows-in-pandas-dataframe-based-on-conditions/ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the following cell, three variables are created, storing in each an array with Petal length values for each Iris species. Each variable is an array of 50 values. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create variable for sepal length \n",
    "# Select rows based a given condition (value of the series 'class') and then only select the value in the series 'petal_length'\n",
    "petal_setosa = data_tabular[data_tabular['species'] == 'setosa']['petal_length']\n",
    "petal_versicolor = data_tabular[data_tabular['species'] == 'versicolor']['petal_length']\n",
    "petal_virginica = data_tabular[data_tabular['species'] == 'virginica']['petal_length']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment to see the arrays for petal lengths for each class \n",
    "#petal_setosa\n",
    "#petal_versicolor\n",
    "#petal_virginica"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The boxplots"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the following cell, three boxplots are created, one for each variable. The boxplots represent the feature Petal Length across the targets (Iris species).\n",
    "\n",
    "About boxplots: https://matplotlib.org/stable/api/_as_gen/matplotlib.axes.Axes.boxplot.html "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a list for all petal length values \n",
    "petal_lengths = [petal_setosa,petal_versicolor,petal_virginica]\n",
    "\n",
    "# Set colors and labels, ticks \n",
    "colors = ['orchid', 'mediumvioletred', 'pink'] \n",
    "median_line = dict(linewidth = 1.5, color = 'yellow' )\n",
    "target_label = target_labels\n",
    "y_ticks = [0.5,1.5,2.5,3.5,4.5,5.5,6.5]\n",
    "\n",
    "# Create subplot\n",
    "fig, ax = plt.subplots() \n",
    "\n",
    "# Plot boxplots\n",
    "# Subplot includes different colors for each feature boxplot, ticks and labels for each feature \n",
    "petal_plot = ax.boxplot(petal_lengths, patch_artist=True, medianprops= median_line, tick_labels=target_label)\n",
    "\n",
    "# assign colors to each feature boxplot \n",
    "# more here: https://matplotlib.org/stable/gallery/statistics/boxplot_color.html#sphx-glr-gallery-statistics-boxplot-color-py\n",
    "for patch, color in zip(petal_plot['boxes'], colors):\n",
    "    patch.set_facecolor(color) \n",
    "\n",
    "# add title \n",
    "ax.set_title('Petal length',weight = 'bold', fontsize = 15)\n",
    "# add labels for axes \n",
    "ax.set_xlabel('\\nIris species')\n",
    "ax.set_ylabel('Measure (in cm)')\n",
    "# add minor ticks to y ax. reference:  https://matplotlib.org/stable/api/_as_gen/matplotlib.axes.Axes.set_yticks.html \n",
    "ax.set_yticks(y_ticks,minor=True)\n",
    "# add grid to y ax. Reference: https://matplotlib.org/stable/api/_as_gen/matplotlib.axes.Axes.grid.html\n",
    "ax.grid(axis='y',color='grey', linestyle='--', linewidth=0.5, alpha = 0.5)\n",
    "\n",
    "# show plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### About the boxplots"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The trend looks similar to that displayed in Task 5, where a scatter plot was created to represent the correlation between Petal length (X ax) and Sepal width (Y ax). The values plotted in the boxplots are the ones plotted in the X ax. \n",
    "\n",
    "As shown in the scatter plot, the boxplots highlight that Setosa species tend to have smaller Petal Length, followed by Versicolor and Virginica. The boxplots also seem to show a direct positivie correlation between Petal Length and the degree of variation of each species: the bigger the dimensions of a species, the more Petal length can vary. \n",
    "\n",
    "In the cells below, each class is examined. Minimum, Maximum, Median and Quartiles are calculated to highlight any specificities and trends in the class. About quartiles and calculating quartiles with Numpy: https://numpy.org/doc/stable/reference/generated/numpy.quantile.html.\n",
    "\n",
    "\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Setosa**\n",
    "\n",
    "Among the three classes, the Setosa species has the **lowest degree of variation** in Petal Length -- min and max are roughly included in the interval 1-2cm, and the values between the 1st and 3rd quartile can vary by less then 0.2cm (values are included in the interval 1.4-1.6cm). Compared to the other Iris species, there is also a high number of outliers, i.e. values that are significantly above or below the normal range of the data. See code cell below.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Max, min, and quartiles (1st quartile, median, 3rd quartile)\n",
    "petal_setosa_min = np.min(petal_setosa)\n",
    "petal_setosa_max = np.max(petal_setosa)\n",
    "petal_setosa_median = np.median(petal_setosa)\n",
    "petal_setosa_1_quantile = np.quantile(petal_setosa, 0.25)\n",
    "petal_setosa_3_quantile = np.quantile(petal_setosa, 0.75)\n",
    "\n",
    "print('Setosa petal length')\n",
    "print(f'Min:\\t{petal_setosa_min}\\tMax:\\t{petal_setosa_max}')\n",
    "print(f'1st q.:\\t{petal_setosa_1_quantile}\\tMedian:\\t{petal_setosa_median}\\t3rd q.:{petal_setosa_3_quantile}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Versicolor**\n",
    "\n",
    "The Versicolor species has a **higher degree of variation**, in particular below the first quartile (minimum value is 3cm, 1st. quartile is 4cm). The minimum number is an outlier, located well below the lower whisker. The distance between minimum and median value is higher than that between median value and maximum (min: 3, median: 4.35, max: 5.1). See complete numbers in the cell code below.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Max, min, and quartiles (1st quartile, median, 3rd quartile)\n",
    "petal_versicolor_min = np.min(petal_versicolor)\n",
    "petal_versicolor_max = np.max(petal_versicolor)\n",
    "petal_versicolor_median = np.median(petal_versicolor)\n",
    "petal_versicolor_1_quartile = np.quantile(petal_versicolor, 0.25)\n",
    "petal_versicolor_3_quartile = np.quantile(petal_versicolor, 0.75)\n",
    "\n",
    "print('Versicolor petal length')\n",
    "print(f'Min:\\t{petal_versicolor_min}\\tMax:\\t{petal_versicolor_max}\\t')\n",
    "print(f'1st q.:\\t{petal_versicolor_1_quartile}\\tMedian:\\t{petal_versicolor_median}\\t3rd q.:\\t{petal_versicolor_3_quartile}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Virginica**\n",
    "\n",
    "As for the Virginica species, the trend looks opposite to that of Iris Versicolor. As for Versicolor, the **degree of variation** is quite high, with long whiskers, and the higher whisker being longer than the the interval between first and third quartile. In this case, however, the maximum is further away from the median value (min: 4.5, median: 5.55, max: 6.9). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Max, min, and quartiles (1st quartile, median, 3rd quartile)\n",
    "petal_virginica_min = np.min(petal_virginica)\n",
    "petal_virginica_max = np.max(petal_virginica)\n",
    "petal_virginica_median = np.median(petal_virginica)\n",
    "petal_virginica_1_quartile = np.quantile(petal_virginica, 0.25)\n",
    "petal_virginica_3_quartile = np.quantile(petal_virginica, 0.75)\n",
    "\n",
    "print('Virginica petal length')\n",
    "print(f'Min:\\t{petal_virginica_min}\\tMax:\\t{petal_virginica_max}\\t')\n",
    "print(f'1st q.:\\t{petal_virginica_1_quartile}\\tMedian:\\t{petal_versicolor_median}\\t3rd q.:\\t{petal_virginica_3_quartile}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Computing correlations "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### About correlations\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section, the Pearson's Correlation Coefficient is calculated for all the features. \n",
    "\n",
    "PCC is a number between -1 and 1 that measures the linear correlation between two sets of data (source: [wikipedia](https://en.wikipedia.org/wiki/Pearson_correlation_coefficient)). In other words, it tells the strength and direction of the relationship between two variables, which means that it reflects how similar the measurements of two variables are across a dataset. (source: [scribbr.com](https://www.scribbr.com/statistics/correlation-coefficient/#:~:text=A%20correlation%20coefficient%20is%20a,variables%20are%20across%20a%20dataset)). In particular:\n",
    "- a correlation between 0 and 1, is a **positive correlation**. This means that y values increase, when x values increase. A correlation of 1 is a perfect positive linear relationship. \n",
    "- a correlation o 0 means that there is **no correlation** between the features.\n",
    "- correlation between 0 and -1 is a **negative correlation**. It means that when x values increase, y values decrease. A correlation of -1 is a perfect negative linear relationship. (source: [Linear Correlation, Real Python](https://realpython.com/numpy-scipy-pandas-correlation-python/#linear-correlation))\n",
    "\n",
    "From a mathematical point of view, \"Pearson's Correlation Coefficient is the ratio between the covariance of two variables and the product of their standard deviations; so, it is essentially a normalized measurement of the covariance, such that the result always has a value between −1 and 1\" Source: [wikipedia](https://en.wikipedia.org/wiki/Pearson_correlation_coefficient).\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Correlation coefficients"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Correlation coefficients can be calculated in multiple ways, using NumPy, SciPy, or Pandas (source: [Real Python](https://realpython.com/numpy-scipy-pandas-correlation-python/#heatmaps-of-correlation-matrices) ). In this case, NumPy's function numpy.corrcoef() is used (source: [NumPY documentation](https://numpy.org/doc/2.2/reference/generated/numpy.corrcoef.html)). With Numpy.corrcoef(), it is possible to provide as paramteres 1-D or 2-D arrays, and calculate the correlation between more than two sets of values at the same time. In this case, correlation coefficients are calculated for all four features at the same time: the x value is a numpy 2-D array where each feature is a column of values. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate correlation coefficients. The parameter rowvar=False is set, so that each column represents a feature. \n",
    "# Numbers are rounded to 2 decimal points, to make them easier to read and use in the heatmap \n",
    "correlation = np.corrcoef(features, rowvar=False).round(decimals=2)\n",
    "\n",
    "print('Correlation coefficients\\n')\n",
    "print('\\t\\tSepal length\\tSepal width\\tPetal length\\tPetal width')\n",
    "print(f'Sepal length\\t{correlation[0,0]}\\t\\t{correlation[0,1]}\\t\\t{correlation[0,2]}\\t\\t{correlation[0,3]}')\n",
    "print(f'Sepal width\\t{correlation[1,0]}\\t\\t{correlation[1,1]}\\t\\t{correlation[1,2]}\\t\\t{correlation[1,3]}')\n",
    "print(f'Petal length\\t{correlation[2,0]}\\t\\t{correlation[2,1]}\\t\\t{correlation[2,2]}\\t\\t{correlation[2,3]}')\n",
    "print(f'Petal width\\t{correlation[3,0]}\\t\\t{correlation[3,1]}\\t\\t{correlation[3,2]}\\t\\t{correlation[3,3]}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Other sources: \n",
    "- [The correlation coefficients between measurement variables](https://www.angela1c.com/projects/iris_project/investigating-the-iris-dataset/#:~:text=The%20correlation%20coefficients%20between%20measurement%20variables%3A&text=a%20strong%20positive%20correlation%20between,Iris%20Virginica%20at%20over%200.86)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Heatmap "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The matrix calculated with NumPy is now used to plot a heatmap showing the correlation relationship between each feature in the dataset. About heatmaps: [official documentation on matplotlib](https://matplotlib.org/stable/gallery/images_contours_and_fields/image_annotated_heatmap.html). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create subplot and plot \n",
    "# About colormaps https://matplotlib.org/stable/users/explain/colors/colormaps.html#sphx-glr-users-explain-colors-colormaps-py\n",
    "fig, ax = plt.subplots()\n",
    "im = ax.imshow(correlation, vmin= -1, vmax = 1, cmap = 'RdPu')\n",
    "\n",
    "# Personalize the plot \n",
    "ax.grid(False)\n",
    "# add feature names as tick labels\n",
    "ax.set_xticks(range(len(feature_labels)),labels=feature_labels, rotation = 45)\n",
    "ax.set_yticks(range(len(feature_labels)),labels=feature_labels)\n",
    "ax.set_title('Feature correlation\\n',fontsize = 15, weight = 'bold')\n",
    "\n",
    "# create a for loop to add coefficient to each cell in the plot \n",
    "for i in range(len(feature_labels)):\n",
    "    for j in range(len(feature_labels)):\n",
    "        text = ax.text(j, i, correlation[i, j],\n",
    "                       ha=\"center\", va=\"center\", color=\"white\", fontsize = 12)\n",
    "        \n",
    "# add colorbar. Reference: https://realpython.com/numpy-scipy-pandas-correlation-python/#linear-correlation \n",
    "cbar = ax.figure.colorbar(im, ax= ax, format='% .2f')\n",
    "cbar.set_label(\"Pearson's correlation coefficient\", rotation=270, labelpad=20)\n",
    "\n",
    "# show\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### About the heatmap "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at the heatmap, the following points can be made: \n",
    "- **Sepal length, Petal length and Petal width** have a positive correlation with each other. The scatter plot on Petal length vs Petal width (task 5) had already highlighted a direct and positive correlation between these two features, but the heatmap shows that there is some positive correlation between Sepal length and Petal length/Petal width, as well. \n",
    "- **Sepal width** is the only feature which has a negative correlation with the other features. It looks like the bigger the petal is, and longer the sepal, the thinner the sepal width is. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Fitting a Simple Linear Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this task, the features from the scatter plot created in Task 5, Petal length and Petal width, are examined again to calculate the **coefficient of determination** between them. The coefficient of determination $R^2$ is \"the proportion of the variation in the dependent variable that is predictable from the independent variable(s)\" ([wikipedia](https://en.wikipedia.org/wiki/Coefficient_of_determination)). This means that $R^2$ expresses how, given a certain Petal length measure, Petal width will vary. The coefficient of determination $R^2$ can be calculated with an analytical approach (that is, with the mathematical formula), or with Scipy. \n",
    "\n",
    "In this part of this section, Scipy is used to calculate $R^2$ and fit a line in the plot. Slope, Intercept and the equation are compared to those calculated with Polyfit in Task 6."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculating $R^2$, slope and intercept"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, scipy.stats.linregress is used to calculate $R$, which is then used to derive the value $R^2$. The function also returns the value of the slope of the line (or gradient, i.e the **m** value from Task 6) and the intercept (i.e value **c** from Task 6). After, these values are used to fit a line in the plot (source: [scipy.stats.linregress](https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.linregress.html))."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use linregress\n",
    "res = sp.stats.linregress(petal_length, petal_width)\n",
    "\n",
    "# show result\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# View R^2 value \n",
    "res.rvalue**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# View slope (corresponding to m)\n",
    "res.slope"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# View intercept (corresponding to c)\n",
    "res.intercept\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The values of slope and intercept are very close to the values m and c calculated in Task 6 with Polyfit. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Re-view m and c\n",
    "m, c"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recreating the plot "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The scatter plot from Task 5 is recreated. The line equation is calculated on the basis of the slope and intercept values from linregress, and the $R^2$ value is added to the legend. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate line equation: y = mx + c \n",
    "scipy_equation = f'W = {res.slope:.2f}L + {res.intercept:.2f}\\n$R^2$ = {res.rvalue**2:.2f}'\n",
    "\n",
    "scipy_equation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare scipy equation with the one calculated with polyfit (result: they are identical)\n",
    "polyfit_equation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recreate the scatter plot \n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "# plot the data -- classes are not differentiated \n",
    "scatter = ax.scatter(petal_length,petal_width, c=target_colormap[targets], marker='8')\n",
    "ax.set_xlabel('Petal length (L)')\n",
    "ax.set_ylabel('Petal width (W)')\n",
    "ax.set_title('Petal size: coefficient of determination')\n",
    "\n",
    "scipy_line = ax.plot(petal_length, res.slope * petal_length + res.intercept, color='green', label = polyfit_equation);\n",
    "\n",
    "ax.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Too many features "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section, a pairplot of the dataset is created with Seaborn ([seaborn.pairplot](https://seaborn.pydata.org/generated/seaborn.pairplot.html))."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A pairplot includes multiple **scatter plots** showing the relationship that each feature has with any of the other features. Each row and each column of the plot correspond to a feature. That feature is plotted on the y ax (when in the row) or on the x ax (when in the column), while another feature is plotted on the other ax. Diagonally, where a variable would be plotted with itself, instead of the scatter plot, \"a **univariate distribution plot** is drawn to show the marginal distribution of the data in each column\" (source: [seaborn.pairplot](https://seaborn.pydata.org/generated/seaborn.pairplot.html)). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare plot legend \n",
    "\n",
    "# Replace column names in the pandas dataframe (Seaborn required df input data)\n",
    "# source : https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.replace.html \n",
    "data_tabular.columns = data_tabular.columns.str.replace('_',' ',regex=False).str.capitalize()\n",
    "\n",
    "# Capitalize species values \n",
    "# source : https://pandas.pydata.org/docs/user_guide/indexing.html \n",
    "data_tabular['Species'] = data_tabular['Species'].str.capitalize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare plot colors \n",
    "\n",
    "# The colors are the same as in the scatter plots above, but in this case a dict is created (for matplotlib, a np array was used)\n",
    "target_palette = {\n",
    "    'Setosa' : 'orchid',\n",
    "    'Versicolor' : 'mediumvioletred',\n",
    "    'Virginica' : 'pink'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the data. \n",
    "# Seaborne requires a pandas dataframe as input data, so the tabular data loaded with pandas are used. \n",
    "sns.pairplot(data_tabular, hue='Species', palette = target_palette)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### About the plot - Project conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Feature correlation**. As hypothesized in Task 8, there seems to be a positive direct correlation beteen Sepal length, Petal length and Petal width. Setosa species are smaller, than dimensions increase for Versicolor and then Virginica species. On the other hand, the smaller these features, the higher is the last feature, Sepal Width. Setosa species have the highest Sepal width dimensions, while the value is lower for Versicolor and Virginica species. \n",
    "\n",
    "- **Feature similarity** Iris Veriscolor and Iris Virginica tend to have more similar features, in some cases with overlapping characteristics, while it is always easier to distinguish Irish Setosa samples. \n",
    "\n",
    "- **Sepal size** seems to be the feature couple with the least degree of correlation -- that is, almost none. Based on the two variables Sepal length and Sepal width, it would not be possible to predict with certainty which class a sample belongs to. However, it might be possible to predict if a sample belongs or not to the Setosa species, since that's the only class whose samples can be distinguished from the others. \n",
    "\n",
    "- **Petal size** as already pointed out in the analysis, between Petal length and Petal width there is such a correlation that, based on these variables, it would be possible to predict which species a sample belongs to. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## End"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
